# -*- coding: utf-8 -*-
"""ResNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hd1Ww2vE_Ogw9W57FWG7QTvRH80mr43c

# 1. Data Processing
"""

import warnings
warnings.filterwarnings('ignore')

import pathlib
import random
import os
import matplotlib.pyplot as plt
import pandas as pd
from PIL import Image
import tensorflow as tf;

from google.colab import drive
drive.mount('/content/drive')

#!unzip "/content/drive/My Drive/Public/state-farm-distracted-driver-detection.zip";

!unzip "/content/imgs.zip";

tf.enable_eager_execution()

# Dataset Parameters - CHANGE HERE
MODE = 'folder' # or 'file', if you choose a plain text file (see above).
# the dataset file or root folder path.
DATASET_PATH = "/content/train"
# not necessary if folder is structured
LABEL_PATH = "/content/state-farm-distracted-driver-detection/driver_imgs_list.csv"

# Image Parameters
N_CLASSES = 10 # CHANGE HERE, total number of classes
IMG_HEIGHT = 200 # CHANGE HERE, the image height to be resized to
IMG_WIDTH = 200 # CHANGE HERE, the image width to be resized to
CHANNELS = 3 # The 3 color channels, change to 1 if grayscale
BATCH_SIZE = 128
imgClassDict = dict({
	"c0": "safe_driving",
	"c1": "texting_right",
	"c2": "talking_on_phone_right",
	"c3": "texting_left",
	"c4": "talking_on_phone_left",
	"c5": "operating_the_radio",
	"c6": "drinking",
	"c7": "reaching_behind",
	"c8": "hair_makeup",
	"c9": "talking_to_passenger",
})
LABELS = [0,1,2,3,4,5,6,7,8,9]
AUTOTUNE = tf.data.experimental.AUTOTUNE
TRAIN_SIZE = None

imgTest = Image.open(DATASET_PATH+ "/c0/img_52332.jpg")

# safe driving
imgTest.size

"""
- From a root folder, that will have a sub-folder containing images for each class
    ```
    ROOT_FOLDER
       |-------- SUBFOLDER (CLASS 0)
       |             |
       |             | ----- image1.jpg
       |             | ----- image2.jpg
       |             | ----- etc...
       |             
       |-------- SUBFOLDER (CLASS 1)
       |             |
       |             | ----- image1.jpg
       |             | ----- image2.jpg
       |             | ----- etc...
    ```
"""
# Reading the dataset
# 2 modes: 'file' or 'folder'
def read_images(dataset_path, mode, batch_size):
    imagePaths, labels = list(), list()
    
     # One Hot Encode the labels
    labels_unique = tf.one_hot(LABELS,len(LABELS))
    
    if mode == 'file':
        # Read dataset file
        with open(dataset_path) as f:
            data = f.read().splitlines()
            print(data)
        for d in data:
            imagePaths.append(d.split(' ')[0])
            labels.append(int(d.split(' ')[1]))
    elif mode == 'folder':
        # An ID will be affected to each sub-folders by alphabetical order
        label = 0
        # List the directory
        try:  # Python 2
            classes = sorted(os.walk(dataset_path).next()[1])
        except Exception:  # Python 3
            classes = sorted(os.walk(dataset_path).__next__()[1])
        # List each sub-directory (the classes)
        for c in classes:
            c_dir = os.path.join(dataset_path, c)
            try:  # Python 2
                walk = os.walk(c_dir).next()
            except Exception:  # Python 3
                walk = os.walk(c_dir).__next__()
            # Add each image to the training set
            for sample in walk[2]:
                # Only keeps jpeg images
                if sample.endswith('.jpg') or sample.endswith('.jpeg'):
                    imagePaths.append(os.path.join(c_dir, sample))
                    labels.append(labels_unique[int(c[1])])
    else:
        raise Exception("Unknown mode.")

    global TRAIN_SIZE
    TRAIN_SIZE = len(imagePaths)
    def preprocessImage(image):
      image = tf.image.decode_jpeg(image, channels=CHANNELS)
      image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])
      image /= 255.0  # normalize to [0,1] range
      return image
    
    def loadImage(path):
      image = tf.read_file(path)
      return preprocessImage(image)   
    print(imagePaths)
    #Shuffle Paths
    imgWLabelPath = list(zip(imagePaths,labels))
    random.shuffle(imgWLabelPath)
    imagePaths,labels = zip(*imgWLabelPath)
    imagePaths = list(imagePaths)
    labels = list(labels)
    
    
     # Convert to Tensor
    imagePaths = tf.data.Dataset.from_tensor_slices(imagePaths)
    labels = tf.data.Dataset.from_tensor_slices(labels)
    

    imageDataset = imagePaths.map(loadImage,
                                  num_parallel_calls = AUTOTUNE)

    dataset = tf.data.Dataset.zip((imageDataset,labels))
    # Running this shuffle overloads my memory so bufferSize is 
    # set lower .
    dataset = dataset.shuffle(buffer_size=10)
    dataset = dataset.repeat()
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=AUTOTUNE)
    return dataset

dataset = read_images(DATASET_PATH,MODE,BATCH_SIZE);

X,Y = next(iter(dataset))
plt.imshow(X[-2])
print(Y[-2])

"""# 2. Loading Pre trained model

## VGG 16
"""

vgg16 = tf.keras.applications.VGG16(
    input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNELS),
    include_top = False,
    weights = 'imagenet'
)
#vgg16.trainable = False

imageBatch,labelBatch = next(iter(dataset))

imageBatch.shape

r = vgg16.predict(tf.expand_dims(imageBatch[0],0))

r.shape

myModel = tf.keras.Sequential([
    vgg16,
    #tf.keras.layers.Conv2D(activation=tf.nn.relu,kernel_size=3,filters=256,strides=2),
    #tf.keras.layers.Conv2D(activation=tf.nn.relu,kernel_size=7,filters=1),
    tf.keras.layers.GlobalAveragePooling2D(),
    #tf.keras.layers.Dense(1000),
    #tf.keras.layers.Dense(256),
    #tf.keras.layers.Dense(128),
    tf.keras.layers.Dense(len(LABELS),activation=tf.nn.softmax)
])

myModel.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001),
              loss=tf.keras.losses.categorical_crossentropy,
              metrics=["accuracy"])

myModel.summary()

myModel.fit(dataset,epochs=1,steps_per_epoch=TRAIN_SIZE,
            shuffle=True)

r = myModel.predict(tf.expand_dims(imageBatch[0],0))

labelBatch[0]



